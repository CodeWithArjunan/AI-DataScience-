{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2905831e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "# Random Forest Classifier with Feature Importance\n",
    "\n",
    "\n",
    "Hello friends,\n",
    "\n",
    "\n",
    "Random Forest is a supervised machine learning algorithm which is based on ensemble learning. In this kernel, I build two Random Forest Classifier models to predict whether a person makes over 50K a year, one with 10 decision-trees and another one with 100 decision-trees. The expected accuracy increases with number of decision-trees in the model. I have demonstrated the **feature selection process** using the Random Forest model to find only the important features, rebuild the model using these features and see its effect on accuracy. I have used the **Income classification data set** for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf0e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc514ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeart_Disease_Prediction.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\Arjun\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\__init__.py:80\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     ArrowDtype,\n\u001b[0;32m     83\u001b[0m     Int8Dtype,\n\u001b[0;32m     84\u001b[0m     Int16Dtype,\n\u001b[0;32m     85\u001b[0m     Int32Dtype,\n\u001b[0;32m     86\u001b[0m     Int64Dtype,\n\u001b[0;32m     87\u001b[0m     UInt8Dtype,\n\u001b[0;32m     88\u001b[0m     UInt16Dtype,\n\u001b[0;32m     89\u001b[0m     UInt32Dtype,\n\u001b[0;32m     90\u001b[0m     UInt64Dtype,\n\u001b[0;32m     91\u001b[0m     Float32Dtype,\n\u001b[0;32m     92\u001b[0m     Float64Dtype,\n\u001b[0;32m     93\u001b[0m     CategoricalDtype,\n\u001b[0;32m     94\u001b[0m     PeriodDtype,\n\u001b[0;32m     95\u001b[0m     IntervalDtype,\n\u001b[0;32m     96\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     97\u001b[0m     StringDtype,\n\u001b[0;32m     98\u001b[0m     BooleanDtype,\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     NA,\n\u001b[0;32m    101\u001b[0m     isna,\n\u001b[0;32m    102\u001b[0m     isnull,\n\u001b[0;32m    103\u001b[0m     notna,\n\u001b[0;32m    104\u001b[0m     notnull,\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     Index,\n\u001b[0;32m    107\u001b[0m     CategoricalIndex,\n\u001b[0;32m    108\u001b[0m     RangeIndex,\n\u001b[0;32m    109\u001b[0m     MultiIndex,\n\u001b[0;32m    110\u001b[0m     IntervalIndex,\n\u001b[0;32m    111\u001b[0m     TimedeltaIndex,\n\u001b[0;32m    112\u001b[0m     DatetimeIndex,\n\u001b[0;32m    113\u001b[0m     PeriodIndex,\n\u001b[0;32m    114\u001b[0m     IndexSlice,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     NaT,\n\u001b[0;32m    117\u001b[0m     Period,\n\u001b[0;32m    118\u001b[0m     period_range,\n\u001b[0;32m    119\u001b[0m     Timedelta,\n\u001b[0;32m    120\u001b[0m     timedelta_range,\n\u001b[0;32m    121\u001b[0m     Timestamp,\n\u001b[0;32m    122\u001b[0m     date_range,\n\u001b[0;32m    123\u001b[0m     bdate_range,\n\u001b[0;32m    124\u001b[0m     Interval,\n\u001b[0;32m    125\u001b[0m     interval_range,\n\u001b[0;32m    126\u001b[0m     DateOffset,\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     to_numeric,\n\u001b[0;32m    129\u001b[0m     to_datetime,\n\u001b[0;32m    130\u001b[0m     to_timedelta,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     Flags,\n\u001b[0;32m    133\u001b[0m     Grouper,\n\u001b[0;32m    134\u001b[0m     factorize,\n\u001b[0;32m    135\u001b[0m     unique,\n\u001b[0;32m    136\u001b[0m     value_counts,\n\u001b[0;32m    137\u001b[0m     NamedAgg,\n\u001b[0;32m    138\u001b[0m     array,\n\u001b[0;32m    139\u001b[0m     Categorical,\n\u001b[0;32m    140\u001b[0m     set_eng_float_format,\n\u001b[0;32m    141\u001b[0m     Series,\n\u001b[0;32m    142\u001b[0m     DataFrame,\n\u001b[0;32m    143\u001b[0m )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\Arjun\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Arjun\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mpandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/missing.pyx:40\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Heart_Disease_Prediction.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe54b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1fb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06620253",
   "metadata": {},
   "source": [
    "## 10. Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bed6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1849bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3caac22",
   "metadata": {},
   "source": [
    " ## 11. Random Forest Classifier model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Random Forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# instantiate the classifier \n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the Test set results\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175be9b",
   "metadata": {},
   "source": [
    "Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822b454",
   "metadata": {},
   "source": [
    "Here, I have build the Random Forest Classifier model with default parameter of `n_estimators = 10`. So, I have used 10 decision-trees to build the model. Now, I will increase the number of decision-trees and see its effect on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc0ed4",
   "metadata": {},
   "source": [
    "## 12. Random Forest Classifier model with 100 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "\n",
    "rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "rfc_100.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred_100 = rfc_100.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f3f33",
   "metadata": {},
   "source": [
    "The model accuracy score with 10 decision-trees is 0.8446 but the same with 100 decision-trees is 0.8521. So, as expected accuracy increases with number of decision-trees in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93be55c",
   "metadata": {},
   "source": [
    "## 13. Find important features with Random Forest model \n",
    "\n",
    "\n",
    "Until now, I have used all the features given in the model. Now, I will select only the important features, build the model using these features and see its effect on accuracy. \n",
    "\n",
    "\n",
    "First, I will create the Random Forest model as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier with n_estimators = 100\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391fca1",
   "metadata": {},
   "source": [
    "Now, I will use the feature importance variable to see feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a695cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the feature scores\n",
    "\n",
    "feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48b01a",
   "metadata": {},
   "source": [
    "We can see that the most important feature is `fnlwgt` and least important feature is `native_country_41`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87176ae8",
   "metadata": {},
   "source": [
    "## 14. Visualize feature scores of the features\n",
    "\n",
    "\n",
    "Now, I will visualize the feature scores with matplotlib and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a seaborn bar plot\n",
    "\n",
    "f, ax = plt.subplots(figsize=(30, 24))\n",
    "ax = sns.barplot(x=feature_scores, y=feature_scores.index, data=df)\n",
    "ax.set_title(\"Visualize feature scores of the features\")\n",
    "ax.set_yticklabels(feature_scores.index)\n",
    "ax.set_xlabel(\"Feature importance score\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd83de5",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "\n",
    "- The above plot confirms that the most important feature is `fnlwgt` and least important feature is `native_country_41`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002b9c7",
   "metadata": {},
   "source": [
    "## 15. Build the Random Forest model on selected features \n",
    "\n",
    "\n",
    "Now, I will drop the least important feature `native_country_41` from the model, rebuild the model and check its effect on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33840bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the least important feature from X_train and X_test\n",
    "\n",
    "X_train = X_train.drop(['native_country_41'], axis=1)\n",
    "\n",
    "X_test = X_test.drop(['native_country_41'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d682940",
   "metadata": {},
   "source": [
    "Now, I will build the random forest model again and check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "print('Model accuracy score with native_country_41 variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54a045",
   "metadata": {},
   "source": [
    "## 16. Confusion matrix \n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "\n",
    "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "\n",
    "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "\n",
    "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
    "\n",
    "\n",
    "\n",
    "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
    "\n",
    "\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4203f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36924a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8db8a",
   "metadata": {},
   "source": [
    "## 17. Classification Report \n",
    "\n",
    "\n",
    "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n",
    "\n",
    "We can print a classification report as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25758c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
